# Kafka Orchestrator Microservice

# ğŸ“– Vue dâ€™ensemble

Ce projet met en place un **orchestrateur** (un service de coordination) basÃ© sur **Apache Kafka ğŸ“¨**.  
Son rÃ´le est dâ€™organiser et de suivre le traitement dâ€™objets de donnÃ©es dÃ©crits dans le fichier **Objets.json ğŸ“‚**.

---

## ğŸ”§ En pratique

- âš™ï¸ Lâ€™orchestrateur dÃ©termine **dans quel ordre** les objets doivent Ãªtre traitÃ©s, en respectant leurs dÃ©pendances.  
- ğŸ“¨ Il envoie des **messages dans Kafka**, ce qui permet aux diffÃ©rents traitements de sâ€™exÃ©cuter **en parallÃ¨le** et de maniÃ¨re **asynchrone**.  
- ğŸ“Š Les objets passent par trois grandes Ã©tapes :  
  1. **Ingestion ğŸ“¥**  
  2. **Standardisation ğŸ”„**  
  3. **Application ğŸš€**  
- ğŸ’» Un **frontend** (interface web) permet de **suivre en direct** lâ€™avancement des traitements.  
- ğŸ³ Le tout est dÃ©ployÃ© avec **Docker** et **Docker Compose**, ce qui facilite lâ€™installation et lâ€™exÃ©cution sur nâ€™importe quelle machine.  

---

## ğŸ“Œ Points clÃ©s du projet

- ğŸ¯ Identifier les **objets finaux** (IDs â‰¥ 3000) et remonter leurs dÃ©pendances jusquâ€™aux **objets sources** (IDs 1000â€“1999).  
- ğŸ§© Optimiser le **graphe des dÃ©pendances** pour Ã©viter de retraiter plusieurs fois les mÃªmes objets.  
- ğŸ“¨ Publier des **Ã©vÃ©nements Kafka** (*ObjectReady*, *ObjectLoaded*, *ObjectFailed*) pour dÃ©clencher et suivre le traitement.  
- ğŸ‘€ Offrir une bonne **visibilitÃ©** grÃ¢ce Ã  des **API ğŸŒ** et un **flux dâ€™Ã©vÃ©nements en temps rÃ©el ğŸ“¡**.  

## ğŸ“Š Architecture du projet


```mermaid
flowchart LR
    subgraph Frontend
        UI["Interface Web (Suivi en temps rÃ©el)"]
    end

    subgraph Orchestrator
        O["Lecture Objets.json"]
        D["Gestion des dÃ©pendances (graphe optimisÃ©)"]
        E["Publication Ã©vÃ©nements Kafka (ObjectReady / Loaded / Failed)"]
    end

    subgraph Kafka
        K["Bus de messages"]
    end

    subgraph Producers
        P1["Ingestion"]
        P2["Standardisation"]
        P3["Application"]
    end

    O --> D --> E --> K
    K --> P1
    K --> P2
    K --> P3
    P1 --> K
    P2 --> K
    P3 --> K
    K --> UI

```

## ğŸ—‚ï¸ Structure du projet

Le projet est organisÃ© comme suit :  

- **âš™ï¸ Orchestrateur (`orchestrator/`)**  
  - Microservice **Python (FastAPI)**.  
  - Charge le fichier **`Objets.json`**, construit un **graphe de dÃ©pendances** et publie les Ã©vÃ©nements **`ObjectReady`** dans **Kafka** en respectant lâ€™ordre topologique.  
  - Contient le **client Kafka**, les **modÃ¨les Pydantic** et la logique dâ€™orchestration.  

- **ğŸ“¨ Producteurs Kafka (`producers/`)** (simulations en Python) :  
  - **`producer_ingest.py`** : traite les objets **1000â€“1999** (â±ï¸ dÃ©lai simulÃ© : 0,5s).  
  - **`producer_standardize.py`** : traite les objets **2000â€“2999** (â±ï¸ dÃ©lai simulÃ© : 0,6s, avec un Ã©chec forcÃ© pour lâ€™ID **2005**).  
  - **`producer_application.py`** : traite les objets **3000+** (â±ï¸ dÃ©lai simulÃ© : 0,8s).  

- **ğŸ’» Frontend (`frontend/`)**  
  - Application **Angular** avec intÃ©gration **SSE**.  
  - Utilise **Nginx** pour servir et proxy les Ã©vÃ©nements Kafka.  

- **ğŸ—ï¸ Infrastructure**  
  - DÃ©ployÃ©e avec **Docker Compose ğŸ³**.  
  - Inclut :  
    - **Zookeeper** ğŸ¦“  
    - **Kafka** ğŸ“¨  
    - **Kafdrop** (interface web de Kafka)  
    - Lâ€™**orchestrateur**, les **producteurs**, et le **frontend**.  
  - **`docker-compose.yml`** : dÃ©finit et lance tout le systÃ¨me (frontend + orchestrateur + producteurs).  

- **ğŸ“¦ DÃ©pendances Python**  
  - **`pyproject.toml`** : gÃ¨re les dÃ©pendances Python via [uv](https://github.com/astral-sh/uv).  


```text
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ src/app
â”‚   â”‚   â”œâ”€â”€ app.component.html    # Frontend UI template
â”‚   â”‚   â”œâ”€â”€ app.component.ts      # Angular component logic
â”‚   â”‚   â””â”€â”€ event.service.ts      # SSE event handling
â”‚   â”œâ”€â”€ Dockerfile                # Docker build for frontend
â”‚   â””â”€â”€ nginx.conf                # Nginx config with SSE proxy
â”œâ”€â”€ orchestrator
â”‚   â”œâ”€â”€ app.py                    # FastAPI orchestrator
â”‚   â”œâ”€â”€ kafka_client.py           # Kafka producer/consumer logic
â”‚   â”œâ”€â”€ models.py                 # Pydantic event models
â”‚   â”œâ”€â”€ orchestrator.py           # Dependency graph and orchestration logic
â”‚   â””â”€â”€ utils.py                  # Utility for loading JSON
â”œâ”€â”€ producers
â”‚   â”œâ”€â”€ producer_ingest.py        # Ingestion simulator
â”‚   â”œâ”€â”€ producer_standardize.py   # Standardization simulator
â”‚   â”œâ”€â”€ producer_application.py   # Application simulator
â”œâ”€â”€ docker-compose.yml            # Orchestrates all services
â”œâ”€â”€ Dockerfile                    # Orchestrator Docker build
â”œâ”€â”€ Objets.json                   # Input data with object configurations
â””â”€â”€ pyproject.toml                # Python dependencies managed with uv
```

---


## ğŸš€ Lancer le projet

### PrÃ©requis
Docker et Docker Compose
Python 3.11 (pour le dÃ©veloppement local, mÃªme si Docker gÃ¨re le runtime)
Node.js 20 (pour la compilation du frontend, pris en charge par Docker)

### Ã‰tapes

#### Cloner le dÃ©pÃ´t
```bash
git clone <url-du-repo>
cd kafka-orchestrator
```
#### Construire et lancer avec Docker Compose
```bash
docker compose up --build
```
#### Services dÃ©marrÃ©s

ğŸ¦“ Zookeeper : port 2181

ğŸ“¨ Kafka : port 9092

âš™ï¸ Orchestrateur : port 8000

ğŸ”„ Producteurs : ingest, standardize, application

ğŸ“Š Kafdrop : port 9000 (interface web de monitoring Kafka)

ğŸ’» Frontend : port 4200 (visualisation en temps rÃ©el des Ã©vÃ©nements)
